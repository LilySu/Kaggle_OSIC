{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]\n",
    "a[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext signature\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\osic-pulmonary-fibrosis-progression.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data\\\\train\\\\ID00007637202177411956430',\n",
       " 'C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data\\\\train\\\\ID00009637202177434476278',\n",
       " 'C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data\\\\train\\\\ID00010637202177584971671']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "train = 'C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data\\\\train'\n",
    "def get_dicom_files(folder):\n",
    "    dcmlist = []\n",
    "    files_in_folder = os.listdir(folder)\n",
    "    for file in files_in_folder:\n",
    "        dcmlist.append(folder+'\\\\'+file)\n",
    "    return dcmlist\n",
    "\n",
    "file_folders = get_dicom_files(train)\n",
    "file_folders[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pydicom\n",
    "\n",
    "\n",
    "def wrangle(Pydicom_FileDataset):\n",
    "    '''Takes the ds object that shows our file metadata\n",
    "    and saves the fields as a dataframe'''\n",
    "    df = pd.DataFrame(Pydicom_FileDataset.values())\n",
    "    df[0] = df[0].apply(lambda x: pydicom.dataelem.DataElement_from_raw(x) if isinstance(x, pydicom.dataelem.RawDataElement) else x)\n",
    "    df['name'] = df[0].apply(lambda x: x.name)\n",
    "    df['value'] = df[0].apply(lambda x: x.value)\n",
    "    df = df[['name', 'value']]\n",
    "    df = df.set_index('name').T\n",
    "    df = df.set_index('Patient ID').reset_index()\n",
    "    return df\n",
    "\n",
    "remaining_files_to_process = file_folders[:-16]\n",
    "\n",
    "# For each patient folder\n",
    "for patient_folder in remaining_files_to_process[:40:-1]:\n",
    "    # The dataframe that we save to is instantiated as a dictionary with all the metadata fields\n",
    "    # Get individual files from file path\n",
    "    dcm_file_list = os.listdir(patient_folder)\n",
    "    # Append our file names to the directory path to create a complete path to our file\n",
    "    dcm_file_path_list = [patient_folder + '/' + i for i in dcm_file_list]\n",
    "    tz_NY = pytz.timezone('America/New_York') \n",
    "    datetime_NY = datetime.now(tz_NY)\n",
    "    current_time = datetime_NY.strftime(\"%B_%d_%I_%M_%S_%p\")\n",
    "    df = pd.DataFrame({'Patient ID': [], \n",
    "                        'Specific Character Set': [], \n",
    "                        'Image Type': [],\n",
    "                        'SOP Instance UID': [], \n",
    "                        'Modality': [], \n",
    "                        'Manufacturer': [],\n",
    "                        \"Manufacturer's Model Name\": [], \n",
    "                        \"Patient's Name\": [], \n",
    "                        \"Patient's Sex\": [],\n",
    "                        'De-identification Method': [], \n",
    "                        'Body Part Examined': [], \n",
    "                        'Slice Thickness': [],\n",
    "                        'KVP': [], \n",
    "                        'Spacing Between Slices': [], \n",
    "                        'Gantry/Detector Tilt': [], \n",
    "                        'Table Height': [],\n",
    "                        'Rotation Direction': [], \n",
    "                        'X-Ray Tube Current': [], \n",
    "                        'Convolution Kernel': [],\n",
    "                        'Patient Position': [], \n",
    "                        'Study Instance UID': [], \n",
    "                        'Series Instance UID': [],\n",
    "                        'Study ID': [], \n",
    "                        'Instance Number': [], \n",
    "                        'Image Position (Patient)': [],\n",
    "                        'Image Orientation (Patient)': [], \n",
    "                        'Frame of Reference UID': [],\n",
    "                        'Position Reference Indicator': [], \n",
    "                        'Slice Location': [], \n",
    "                        'Samples per Pixel': [],\n",
    "                        'Photometric Interpretation': [], \n",
    "                        'Rows': [], \n",
    "                        'Columns': [], \n",
    "                        'Pixel Spacing': [],\n",
    "                        'Bits Allocated': [], \n",
    "                        'Bits Stored': [], \n",
    "                        'High Bit': [], \n",
    "                        'Pixel Representation': [],\n",
    "                        'Window Center': [], \n",
    "                        'Window Width': [], \n",
    "                        'Rescale Intercept': [], \n",
    "                        'Rescale Slope': [],\n",
    "                        'Pixel Data': []})\n",
    "    for single_file_path in dcm_file_path_list:\n",
    "        # Process the .dcm files as a Pydicom FileDataset object\n",
    "        try:\n",
    "            ds = pydicom.dcmread(single_file_path)  \n",
    "            # Convert metadata to a temporary dataframe\n",
    "            single_patient_df = wrangle(ds)\n",
    "            # Append to the previously saved dataframe \n",
    "            df = df.append(single_patient_df)\n",
    "            # Incrementally save each iteration of for loop to dataframe as a csv\n",
    "            df.to_csv(f'C:\\\\Users\\\\lilyx\\\\Kaggle_OSIC\\\\data\\\\train_pydicom_fileDataset\\\\{current_time}_{patient_folder[38::]}_OSIC_patient_dcm.csv')\n",
    "        except:\n",
    "            continue\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple rows with same patient\n",
    "# assumption you should learn is each row is separate patient\n",
    "\n",
    "# cross validataion split between pateient \n",
    "\n",
    "# encode categories as\n",
    "\n",
    "# histogram gradient boosting\n",
    "# xgboost, extreme ensemble tree boosting frameworks\n",
    "# light gbm histogram gradient boosting \n",
    "# histogram - makes things fast, for numerical features, it will be broken to quantiles, 256 quantiles, distrete ties to feature space\n",
    "# when you grow trees\n",
    "# samples are sorted, scan through bins to find splits of your leaves\n",
    "# lightgvm other trick - it is parallelized xgboost is using cuda and open mp\n",
    "# histograms parallelizes, histograms - if left tree node histogram can subtract parent from left tree node to get to the other node\n",
    "# computer science tricks - lgiht gvm \n",
    "# regular gradient boosting - gradient boost - 100% faster\n",
    "\n",
    "# microsoft hummingbird prediction converts a tree based model into a tpu\n",
    "# most algorithmns can \n",
    "\n",
    "# qpy - replace numpy with qpy on gpu - \n",
    "# https://cupy.dev/ \n",
    "# https://azuredata.microsoft.com/articles/ebd95ec0-1eae-44a3-90f5-c11f5c916d15\n",
    "# https://scnakandala.github.io/papers/TR_2020_Hummingbird.pdf\n",
    "# https://www.meetup.com/Seattle-WiDS-Meetup/\n",
    "\n",
    "# using ml to predict patients - clinical studies for health records\n",
    "# source validity\n",
    "\n",
    "# ecdc for data sources globally, you have to have the % positive, and testing per capita, hospitalizations, \n",
    "# we don't have great data on equity (race differences) no body in county to put statistics together\n",
    "# big health departments attract top talent\n",
    "\n",
    "# communative distribution instead of histograms\n",
    "\n",
    "# countries are not age adjusted, comparing countries\n",
    "# vital statistics ie birth registrations may not have accounted for changes in population, but census is a 10-year event\n",
    "# vital records from state, you apply you \n",
    "# national center for health statistics - globally - UN population diviion se\n",
    "# ngo nonprofit - cancer registry program, strategically, covid fell into lap, to backstop until hiring statistician, \n",
    "# plan project and execute, set up systems to collect data on cancer, hard to practice basic skills. \n",
    "\n",
    "# nvidia - key contributors, they look at what teams do, they optimize what teams do. \n",
    "\n",
    "# worker made coorperative movement\n",
    "\n",
    "# transducer monads closure, atoms no closure tests something else, why do you let linter CLJ kondo static type checker\n",
    "# structural editing - for lisp for parentesis as a guide to write code # you can feed a line of code into function and have\n",
    "# it be evaluated by the reader - dynamically execute on the fly during compile and run time. \n",
    "# built on top of jvm, as much efficient practicial code, almost no syntax\n",
    "\n",
    "# language attention, huggingface has opensource transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KaggleKernel",
   "language": "python",
   "name": "kagglekernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
